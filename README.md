# âš¡ Neon Cyber â€” Explainable Diabetes AI Dashboard

An interactive neon-themed **Explainable AI dashboard** for diabetes risk prediction with:

- ğŸ©º Doctor Dashboard
- ğŸ”§ What-If Risk Simulator
- ğŸ§  SHAP Explainability View
- âš– Fairness & Trust Analysis
- ğŸ¨ Cyber-Neon UI Theme

This project demonstrates **Responsible AI in Healthcare** with transparency, fairness, explainability, and patient-centric interpretation.

---

## ğŸ›¡ Badges

![Status](https://img.shields.io/badge/Status-Active-brightgreen)
![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red)
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Explainable AI](https://img.shields.io/badge/Explainable_AI-SHAP-green)
![Healthcare AI](https://img.shields.io/badge/Domain-Healthcare-purple)
![Responsible AI](https://img.shields.io/badge/Responsible_AI-Fairness-orange)

---

## ğŸ–¼ Project Screenshots

### ğŸ©º Doctor Dashboard
![Doctor Dashboard](assets/screenshot_dashboard.png)

### ğŸš¨ High-Risk Alert
![High Risk](assets/screenshot_high_risk_alert.png)

### ğŸ”§ What-If Simulator
![Simulator](assets/screenshot_simulator.png)

### ğŸ§  Explainability View
![Explainability](assets/screenshot_explainability.png)

### âš– Fairness & Trust Portal
![Fairness](assets/screenshot_fairness.png)

---

## ğŸ† Key Features

âœ” Real-time diabetes risk scoring  
âœ” Neon cyber UI inspired interface  
âœ” Patient-friendly interpretation text  
âœ” SHAP explainability (local + global)  
âœ” What-If lifestyle change simulator  
âœ” Bias & subgroup risk analysis  
âœ” Recruiter-friendly portfolio project  

---

## ğŸ§  Explainable AI Capabilities

This project focuses on **transparent ML models**, including:

- SHAP value heatmaps
- Waterfall explanation plot
- Feature contribution tables
- Plain-language reasoning text
- Instance-level explanations

Example interpretation:

> High glucose and BMI are the primary contributors to increased estimated diabetes risk in this patient.

---

## âš– Responsible AI & Governance

Included capabilities:

- Bias & fairness comparison across groups  
- Transparency score indicator  
- Consent acknowledgement checkbox  
- Risk-aware warning messages  

This aligns with:

- Responsible AI guidelines  
- Model Risk Governance concepts  
- Healthcare AI expectations  

---

## ğŸ§© Tech Stack

- Python
- Streamlit
- Scikit-Learn
- SHAP
- Plotly
- Pandas / NumPy

---

## ğŸš€ Run Locally

### 1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/tonumayworkspace-creator/neon-explainable-diabetes-ai.git
cd neon-explainable-diabetes-ai
```

### 2ï¸âƒ£ Create virtual environment (recommended)

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Launch app

```bash
streamlit run app.py
```

---

## ğŸ“ Model Card and License

- See `MODEL_CARD.md` for detailed documentation
- Licensed under the MIT License (`LICENSE` file)

---

## ğŸ›‘ Medical Disclaimer

This software is intended **for research and education only**.

It is **NOT a medical device** and must **NOT** be used for medical diagnosis or treatment.

Always consult licensed clinicians.

---

## ğŸ‘¤ Author

**Tonumay Bhattacharya**  
Data Science | Machine Learning | Generative AI | Healthcare AI

â­ If you like this project, please star the repository.
